{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "import evaluate\n",
    "\n",
    "print(platform.platform())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/madisonthantu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFs:**\n",
    "- https://huggingface.co/docs/transformers/tasks/summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_name = 'reddit'\n",
    "model = 'T5'\n",
    "generation = 'Gen0'\n",
    "output_dir=os.path.join(dataset_name, model, generation)\n",
    "output_dir\n",
    "\n",
    "use_small_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "    num_rows: 211\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tifu = load_dataset(\"reddit_tifu\", 'long')['train']\n",
    "tifu_small = tifu.shard(num_shards=200, index=0)\n",
    "tifu_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tifu = tifu.add_column\n",
    "doc_sent_len = [len(re.findall(r'\\w+', sentence)) for sentence in tifu['documents']]\n",
    "summ_sent_len = [len(re.findall(r'\\w+', sentence)) for sentence in tifu['tldr']]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, tight_layout=True)\n",
    "\n",
    "axs[0].hist(doc_sent_len, bins=max(doc_sent_len));\n",
    "axs[0].set_xlabel('Number of words')\n",
    "axs[0].set_ylabel('Number of documents')\n",
    "axs[1].hist(summ_sent_len, bins=max(summ_sent_len));\n",
    "axs[1].set_xlabel('Number of words')\n",
    "axs[1].set_ylabel('Number of summaries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used small dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "        num_rows: 168\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "        num_rows: 43\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_small_dataset:\n",
    "    print(\"Used small dataset\")\n",
    "    dataset = tifu_small.train_test_split(test_size=0.2)\n",
    "else:\n",
    "    dataset = tifu.train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> title: needing toilet paper\n",
      ">> documents: i'm still sitting on my throne pondering about this, so i guess for once it did happen today....\n",
      ">> summary: i asserted my dominance over my mother\n",
      "\n",
      ">> title: suggesting my friend put her bra in the microwave to dry it off...\n",
      ">> documents: this story happened six years ago during my last year of high school and a few weeks after my 18th birthday (at a point when teenage derpness is no excuse). ...\n",
      ">> summary: jokingly told my friend to put her bra in the microwave to dry it out and accidentally set it on fire.\n",
      "\n",
      ">> title: drinking root beer. out of the wrong can.\n",
      ">> documents: in the great vein of tifu posts that happened anytime but today:...\n",
      ">> summary: drank a&w with added ingredients. roaches. fml.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        title, doc, summ = example['title'], example['documents'], example['tldr']\n",
    "        print(f\">> title: {title}\")\n",
    "        print(\">> documents: {0}...\".format(doc[:doc.find('\\n')]))\n",
    "        print(f\">> summary: {summ}\\n\")\n",
    "\n",
    "show_samples(dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t5-small': 512, 't5-base': 512, 't5-large': 512, 't5-3b': 512, 't5-11b': 512}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'team': 11650,\n",
       " '▁funcție': 20645,\n",
       " '▁Messiah': 31908,\n",
       " '▁abdomen': 24729,\n",
       " 'themed': 24186,\n",
       " 'h': 107,\n",
       " '▁galaxy': 24856,\n",
       " 'hog': 18330,\n",
       " '▁trained': 4252,\n",
       " '210': 15239,\n",
       " 'ologi': 11697,\n",
       " '▁regl': 17186,\n",
       " '▁Along': 8529,\n",
       " 'stände': 14634,\n",
       " 'cruising': 27471,\n",
       " 'clo': 3903,\n",
       " '▁tasting': 12246,\n",
       " '▁LOVE': 10315,\n",
       " 'ultimul': 15211,\n",
       " '▁sexuelle': 27768,\n",
       " '(2009)': 25812,\n",
       " 'grabbing': 26910,\n",
       " '▁imitation': 30815,\n",
       " '▁Anderson': 11825,\n",
       " '▁Yellow': 12035,\n",
       " 'eed': 6958,\n",
       " '▁comunicare': 19190,\n",
       " '▁10,': 10372,\n",
       " '▁neglect': 18339,\n",
       " '▁Bark': 24828,\n",
       " '1700': 26774,\n",
       " '▁joyful': 26128,\n",
       " 'listen': 20368,\n",
       " '▁Acces': 25679,\n",
       " '▁Zusätzlich': 22894,\n",
       " '▁necesitate': 29292,\n",
       " '▁slide': 9116,\n",
       " '▁fresh': 1434,\n",
       " 'lik': 8654,\n",
       " '▁Ministries': 31458,\n",
       " '▁garantie': 12073,\n",
       " '▁genotyp': 31595,\n",
       " '▁declining': 24772,\n",
       " 'CI': 3597,\n",
       " '▁trust': 2019,\n",
       " 'Aceasta': 9721,\n",
       " '▁choir': 20778,\n",
       " 'heure': 9419,\n",
       " '▁Inc': 1542,\n",
       " '▁Stoff': 16016,\n",
       " '▁Materialien': 20636,\n",
       " 'CBC': 27403,\n",
       " '▁pan': 2131,\n",
       " 'Royce': 30840,\n",
       " '▁ethics': 16083,\n",
       " '▁Today': 1960,\n",
       " 'numite': 30909,\n",
       " '▁gadget': 13195,\n",
       " '▁shooting': 5262,\n",
       " '▁documentation': 7192,\n",
       " 'untouched': 31729,\n",
       " 'ătoare': 9097,\n",
       " '▁wollen': 6056,\n",
       " 'focuses': 6915,\n",
       " 'aurez': 17424,\n",
       " 'ponent': 9977,\n",
       " '▁Repeat': 20469,\n",
       " '▁represents': 5475,\n",
       " 'scheid': 10726,\n",
       " 'izată': 20257,\n",
       " 'oversized': 24698,\n",
       " '▁Edgar': 27151,\n",
       " '▁regret': 9867,\n",
       " 'PJ': 23953,\n",
       " '▁heap': 24459,\n",
       " '▁Thrones': 29344,\n",
       " '▁causes': 4110,\n",
       " '▁răni': 28498,\n",
       " 'aggregat': 31761,\n",
       " '▁spezielle': 17910,\n",
       " 'state': 5540,\n",
       " '▁shows': 1267,\n",
       " '▁Valentin': 22606,\n",
       " 'lash': 8058,\n",
       " '▁Radi': 14501,\n",
       " 'LLP': 26649,\n",
       " '▁continuous': 7558,\n",
       " '▁foremost': 19839,\n",
       " '▁vice': 6444,\n",
       " '▁kritisch': 28761,\n",
       " 'Anzeige': 23557,\n",
       " '▁decades': 4160,\n",
       " '▁Aroma': 24293,\n",
       " '▁tras': 12656,\n",
       " '▁VIP': 14273,\n",
       " '▁stu': 21341,\n",
       " '▁collar': 13756,\n",
       " '▁conduce': 21255,\n",
       " '▁Private': 7086,\n",
       " 'har': 3272,\n",
       " '▁Fame': 20758,\n",
       " '▁endorse': 24861,\n",
       " '▁Ski': 7409,\n",
       " '▁keeps': 5689,\n",
       " 'formulaire': 23084,\n",
       " '▁step': 1147,\n",
       " 'accueil': 11134,\n",
       " '▁overwhelming': 11316,\n",
       " 'enceinte': 28572,\n",
       " '▁wearing': 5119,\n",
       " '▁Camill': 28347,\n",
       " '▁Conservation': 18260,\n",
       " '▁Conditioner': 24668,\n",
       " 'état': 7795,\n",
       " 'wä': 7497,\n",
       " '▁diagnos': 28252,\n",
       " 'alegerea': 21749,\n",
       " '▁sute': 21285,\n",
       " '▁manifest': 6571,\n",
       " '▁nie': 6691,\n",
       " 'any': 6820,\n",
       " 'effective': 8993,\n",
       " 'tested': 23775,\n",
       " '▁Station': 5939,\n",
       " 'ța': 8456,\n",
       " '▁rough': 8678,\n",
       " 'Why': 17891,\n",
       " '▁récompense': 31705,\n",
       " '▁francez': 19985,\n",
       " 'cross': 11465,\n",
       " '▁manevr': 30723,\n",
       " '▁kontinuierlich': 29968,\n",
       " 'Während': 13392,\n",
       " 'ados': 14073,\n",
       " '▁slippery': 31071,\n",
       " '▁cups': 12294,\n",
       " '▁lesser': 18605,\n",
       " 'aţia': 10984,\n",
       " '▁surpass': 25678,\n",
       " '▁întrerup': 31888,\n",
       " '<extra_id_89>': 32010,\n",
       " '▁producer': 8211,\n",
       " '▁oarec': 27793,\n",
       " '▁congratulations': 29138,\n",
       " 'utilizatorii': 29477,\n",
       " '▁station': 2478,\n",
       " '▁comun': 6252,\n",
       " '▁Flugzeug': 30702,\n",
       " '▁investors': 4367,\n",
       " 'sted': 6265,\n",
       " 'Friday': 31157,\n",
       " 'Providing': 22470,\n",
       " 'arhi': 16611,\n",
       " 'wahren': 28350,\n",
       " '▁gemeinsam': 6602,\n",
       " '▁fauna': 29908,\n",
       " '▁painted': 7445,\n",
       " '▁clearing': 19390,\n",
       " '▁solar': 3693,\n",
       " '▁Nicht': 7989,\n",
       " '▁Commission': 3527,\n",
       " '▁marketers': 17855,\n",
       " 'emplacement': 25287,\n",
       " '▁increased': 1936,\n",
       " '▁rainbow': 21567,\n",
       " '▁removal': 4614,\n",
       " 'Source': 23799,\n",
       " '▁nonprofit': 11069,\n",
       " 'MF': 13286,\n",
       " '▁immigrants': 16096,\n",
       " 'persoanele': 15234,\n",
       " '▁innovations': 15858,\n",
       " 'ană': 14781,\n",
       " 'maßnahmen': 26540,\n",
       " 'valid': 27769,\n",
       " 'Plus': 22571,\n",
       " '▁Mittelpunkt': 28366,\n",
       " 'crystalline': 31900,\n",
       " '▁abrupt': 25119,\n",
       " '▁Shuttle': 28099,\n",
       " '▁développer': 16710,\n",
       " 'ätz': 19711,\n",
       " '▁1/2\"': 23562,\n",
       " '▁cream': 3022,\n",
       " '▁addressed': 8705,\n",
       " '▁dye': 15302,\n",
       " 'If': 5801,\n",
       " 'lädt': 26959,\n",
       " '▁1911': 28623,\n",
       " '“': 735,\n",
       " '225': 20489,\n",
       " '▁România': 3514,\n",
       " '▁Nacht': 12822,\n",
       " '▁Bil': 14918,\n",
       " 'kins': 7815,\n",
       " '▁identific': 23318,\n",
       " '▁interesant': 13656,\n",
       " '▁article': 1108,\n",
       " 'UT': 6675,\n",
       " '▁de': 20,\n",
       " 'anny': 15159,\n",
       " '▁keiner': 18904,\n",
       " 'époque': 14971,\n",
       " 'Vision': 31535,\n",
       " '▁bucurie': 22659,\n",
       " '▁grid': 8634,\n",
       " '▁deplasare': 30268,\n",
       " '▁adequately': 22538,\n",
       " '▁Cottage': 22194,\n",
       " '▁arrives': 16732,\n",
       " '▁Exist': 17061,\n",
       " '▁Br': 6806,\n",
       " '▁Cristina': 27800,\n",
       " 'ductive': 28668,\n",
       " 'lassung': 20766,\n",
       " '▁close': 885,\n",
       " '▁Verfügung': 7182,\n",
       " '▁coal': 8416,\n",
       " '▁killed': 4792,\n",
       " '▁fencing': 24141,\n",
       " '▁Derma': 28206,\n",
       " '▁încadr': 30391,\n",
       " '▁matur': 18677,\n",
       " 'Lastly': 19807,\n",
       " 'a': 9,\n",
       " '▁Pou': 20313,\n",
       " 'prezintă': 22258,\n",
       " 'private': 26881,\n",
       " 'bleed': 27779,\n",
       " 'ers': 277,\n",
       " '▁homes': 2503,\n",
       " '▁Legal': 11281,\n",
       " '▁Chicken': 16451,\n",
       " '▁Daniel': 4173,\n",
       " '9,000': 23938,\n",
       " '▁Bio': 3318,\n",
       " 'ucked': 15318,\n",
       " '▁alimentare': 20097,\n",
       " 'issuance': 30935,\n",
       " '▁coupon': 8133,\n",
       " '▁contacts': 11463,\n",
       " '▁Recent': 17716,\n",
       " '▁occupation': 13792,\n",
       " 'woke': 18423,\n",
       " 'functional': 21601,\n",
       " '▁Spectrum': 29998,\n",
       " 'gesteuert': 31616,\n",
       " 'heightened': 30714,\n",
       " '▁stipulate': 28713,\n",
       " 'gator': 19306,\n",
       " 'presently': 25390,\n",
       " '▁tour': 1552,\n",
       " '▁entre': 1721,\n",
       " 'ibly': 15596,\n",
       " '▁year': 215,\n",
       " '▁Entrepreneur': 26696,\n",
       " '▁cea': 2511,\n",
       " 'ruf': 10977,\n",
       " '▁squad': 12025,\n",
       " 'ufgrund': 10378,\n",
       " '▁decline': 7198,\n",
       " '▁echipe': 20183,\n",
       " '▁cogn': 23179,\n",
       " 'RIP': 26017,\n",
       " '▁Ho': 1546,\n",
       " '▁ethnic': 11655,\n",
       " 'Work': 12492,\n",
       " '▁Four': 5933,\n",
       " '▁unaware': 24111,\n",
       " 'asca': 8419,\n",
       " 'wag': 15238,\n",
       " 'brewed': 31100,\n",
       " '▁Mess': 6598,\n",
       " '▁Bh': 16332,\n",
       " 'UE': 5078,\n",
       " '▁Pink': 12070,\n",
       " '102': 14388,\n",
       " 'oji': 21892,\n",
       " '▁officially': 8441,\n",
       " '▁posé': 26679,\n",
       " '▁Alkohol': 28139,\n",
       " 'stage': 10705,\n",
       " 'arbeiten': 7987,\n",
       " 'depth': 10437,\n",
       " '▁we': 62,\n",
       " '▁portray': 17611,\n",
       " '▁suggér': 31967,\n",
       " 'meiner': 9221,\n",
       " '▁Wort': 10507,\n",
       " 'rained': 10761,\n",
       " '▁Rez': 18100,\n",
       " '▁anticipat': 27538,\n",
       " '▁apropiere': 20652,\n",
       " 'cola': 12600,\n",
       " '▁faculty': 6040,\n",
       " '▁03': 12811,\n",
       " 'APA': 23649,\n",
       " 'â': 1439,\n",
       " 'col': 3297,\n",
       " 'git': 12651,\n",
       " 'verwaltung': 22793,\n",
       " 'bel': 2370,\n",
       " '▁zone': 2901,\n",
       " 'Sie': 23357,\n",
       " '▁died': 3977,\n",
       " '▁télécharger': 25884,\n",
       " '▁dial': 10362,\n",
       " '▁Communities': 28086,\n",
       " '▁Vic': 12060,\n",
       " '▁Ob': 4249,\n",
       " '▁altogether': 16889,\n",
       " '▁|': 1820,\n",
       " '▁Virginia': 5382,\n",
       " '▁Following': 6851,\n",
       " '▁delivers': 9250,\n",
       " '▁forte': 14188,\n",
       " '▁dedicat': 15778,\n",
       " '▁Singh': 16738,\n",
       " '▁Beg': 10129,\n",
       " 'marketed': 26640,\n",
       " '▁Numero': 25638,\n",
       " '404': 25285,\n",
       " '▁Assess': 28955,\n",
       " '▁FL': 7212,\n",
       " '▁throughout': 1019,\n",
       " '▁merveille': 27015,\n",
       " '▁beau': 9743,\n",
       " 'roll': 4046,\n",
       " '▁metallic': 18813,\n",
       " 'ţei': 12610,\n",
       " '▁collègue': 29239,\n",
       " 'ausbildung': 30878,\n",
       " 'ără': 13525,\n",
       " '▁Apply': 11899,\n",
       " 'ager': 9754,\n",
       " 'needed': 25797,\n",
       " 'informatiile': 26958,\n",
       " '1000': 16824,\n",
       " 'animation': 26425,\n",
       " 'omni': 16378,\n",
       " 'cade': 6615,\n",
       " '▁Regard': 12312,\n",
       " 'schen': 3878,\n",
       " '▁Vet': 20495,\n",
       " '▁neben': 7709,\n",
       " 'George': 31317,\n",
       " '▁lineup': 15561,\n",
       " '▁refreshing': 13132,\n",
       " '▁seule': 10534,\n",
       " '▁hinweg': 29671,\n",
       " '▁Speech': 26351,\n",
       " '▁Cassi': 22889,\n",
       " '▁peut': 1351,\n",
       " 'ating': 1014,\n",
       " 'ем': 25083,\n",
       " '▁steam': 7222,\n",
       " '▁frustrating': 16591,\n",
       " '▁reviewed': 9112,\n",
       " '▁Responsible': 29088,\n",
       " '▁lifetime': 6556,\n",
       " '-13': 13056,\n",
       " '▁exposure': 4773,\n",
       " '▁indiferent': 15399,\n",
       " '▁citi': 16545,\n",
       " '▁deadline': 7183,\n",
       " 'être': 2680,\n",
       " '▁Perspektive': 27524,\n",
       " '▁penetration': 25723,\n",
       " 'chester': 13263,\n",
       " '▁speaker': 5873,\n",
       " '▁blend': 4764,\n",
       " '▁cozy': 14384,\n",
       " '▁Container': 24191,\n",
       " 'wishing': 19865,\n",
       " '▁Political': 19289,\n",
       " '▁délai': 14158,\n",
       " '▁Burke': 27575,\n",
       " '<extra_id_29>': 32070,\n",
       " 'schritt': 15755,\n",
       " '▁apărare': 30635,\n",
       " '▁pieces': 2161,\n",
       " '▁Ta': 2067,\n",
       " '▁ears': 11581,\n",
       " '▁Cold': 13331,\n",
       " '▁alignment': 14632,\n",
       " '▁hopefully': 8858,\n",
       " '▁microphone': 18701,\n",
       " 'deserved': 21348,\n",
       " 'amitié': 31989,\n",
       " '▁cert': 12276,\n",
       " '▁mărturi': 26055,\n",
       " '▁strict': 6926,\n",
       " 'nehmer': 16477,\n",
       " 'beneficiar': 29163,\n",
       " '▁Everything': 7462,\n",
       " '▁disappointment': 19142,\n",
       " '▁edges': 9804,\n",
       " '▁Mortgage': 20922,\n",
       " '▁scissors': 28958,\n",
       " '▁mai': 187,\n",
       " '▁Meadow': 23302,\n",
       " '▁analiza': 18138,\n",
       " '▁chest': 5738,\n",
       " '▁delayed': 16124,\n",
       " 'cumva': 25455,\n",
       " '▁Elder': 21297,\n",
       " '▁medici': 18170,\n",
       " '▁Someone': 16471,\n",
       " '▁Buffet': 25128,\n",
       " '▁introduce': 4277,\n",
       " '▁Motiv': 17252,\n",
       " 'TECH': 25036,\n",
       " '▁mândr': 31060,\n",
       " '▁aussi': 1292,\n",
       " '▁finally': 2031,\n",
       " '▁partener': 15105,\n",
       " '▁Personal': 4239,\n",
       " '▁apart': 3943,\n",
       " '▁Orientierung': 31865,\n",
       " '▁gefördert': 29876,\n",
       " '▁orchestra': 13873,\n",
       " 'light': 2242,\n",
       " 'town': 3540,\n",
       " '▁conversation': 3634,\n",
       " 'iți': 7399,\n",
       " '850': 17246,\n",
       " '▁running': 1180,\n",
       " '▁confession': 26838,\n",
       " '▁extend': 4285,\n",
       " 'fass': 12837,\n",
       " '▁souligne': 27069,\n",
       " '▁prezenta': 12006,\n",
       " '▁Going': 15312,\n",
       " '5)': 9120,\n",
       " 'NAS': 21277,\n",
       " 'mputation': 31148,\n",
       " '▁Department': 1775,\n",
       " '▁inter': 1413,\n",
       " '▁board': 1476,\n",
       " 'money': 28442,\n",
       " '▁elektrisch': 31517,\n",
       " '▁Topic': 18059,\n",
       " 'ilor': 967,\n",
       " 'stitution': 17448,\n",
       " '▁dispozitie': 20928,\n",
       " '▁builders': 19334,\n",
       " '▁dédié': 17991,\n",
       " 'lining': 9424,\n",
       " '▁sodium': 19049,\n",
       " '▁Förderung': 24511,\n",
       " '▁Ham': 5845,\n",
       " '▁speaks': 12192,\n",
       " '▁celebrities': 20076,\n",
       " 'iques': 5125,\n",
       " '▁bilingual': 30521,\n",
       " 'lude': 21135,\n",
       " 'clu': 10562,\n",
       " '▁Specialist': 13712,\n",
       " '▁articole': 18367,\n",
       " '▁Garant': 21496,\n",
       " '▁counsel': 11189,\n",
       " '▁präsentiert': 19833,\n",
       " '▁Memory': 19159,\n",
       " '▁sides': 4458,\n",
       " '▁laboratories': 25642,\n",
       " '▁Skills': 19559,\n",
       " '▁wondered': 15999,\n",
       " 'ACK': 15339,\n",
       " '▁grinding': 10784,\n",
       " '▁proaspat': 29752,\n",
       " '▁agresiv': 31080,\n",
       " '▁undertaking': 16529,\n",
       " '▁Television': 21922,\n",
       " '▁poliţi': 25137,\n",
       " 'if': 99,\n",
       " '▁Suzuki': 26855,\n",
       " '▁Konzept': 15901,\n",
       " '▁Re': 419,\n",
       " 'gung': 15774,\n",
       " '▁Leopard': 31880,\n",
       " 'buted': 29261,\n",
       " '▁asemenea': 3419,\n",
       " '▁drug': 2672,\n",
       " '▁representation': 6497,\n",
       " '▁Pope': 17384,\n",
       " '▁summit': 13385,\n",
       " '▁Kill': 14450,\n",
       " 'lac': 9700,\n",
       " '▁superstar': 27375,\n",
       " 'rium': 11879,\n",
       " '▁qui': 285,\n",
       " 'geschlossen': 14943,\n",
       " 'lowered': 22055,\n",
       " '▁Schnitt': 25397,\n",
       " '▁Kosovo': 30072,\n",
       " '▁regizor': 31310,\n",
       " '▁is': 19,\n",
       " '▁execut': 9362,\n",
       " 'ste': 849,\n",
       " '▁anume': 16074,\n",
       " 'cro': 2771,\n",
       " '▁aus': 403,\n",
       " '▁produselor': 14995,\n",
       " 'armée': 24747,\n",
       " '▁Olivia': 25051,\n",
       " '▁Forward': 25633,\n",
       " '▁Mickey': 26886,\n",
       " 'wildly': 28890,\n",
       " '▁recognised': 14869,\n",
       " '▁Ger': 5744,\n",
       " 'au': 402,\n",
       " '▁Rate': 13002,\n",
       " '▁Assessment': 15186,\n",
       " 'teig': 25696,\n",
       " '▁Connecticut': 15505,\n",
       " '▁Ersatzteile': 27634,\n",
       " '▁compris': 8315,\n",
       " '▁Sub': 3325,\n",
       " 'qual': 11433,\n",
       " 'ABILITY': 27474,\n",
       " '▁table': 953,\n",
       " 'sie': 2452,\n",
       " 'rast': 20484,\n",
       " '▁admis': 24289,\n",
       " 'rebounds': 23768,\n",
       " '▁antagonist': 30619,\n",
       " 'ând': 1833,\n",
       " 'q': 1824,\n",
       " '▁finden': 2706,\n",
       " '▁7.': 4306,\n",
       " 'technik': 11193,\n",
       " 'trop': 12395,\n",
       " 'thro': 8514,\n",
       " 'Kon': 18620,\n",
       " '▁anunțat': 27234,\n",
       " '▁gelungen': 22847,\n",
       " '▁crește': 23975,\n",
       " '▁dinner': 2634,\n",
       " '▁conceal': 23808,\n",
       " '▁Bermuda': 30441,\n",
       " '▁pets': 8636,\n",
       " '▁Stay': 8026,\n",
       " '▁survival': 9990,\n",
       " '▁vessel': 12662,\n",
       " 'gezahlt': 31872,\n",
       " '▁harmony': 18362,\n",
       " '▁departure': 12028,\n",
       " '▁piscine': 17314,\n",
       " '▁Garage': 13778,\n",
       " '▁hits': 8046,\n",
       " 'square': 19687,\n",
       " 'vases': 31776,\n",
       " '▁Hay': 8567,\n",
       " 'Konzern': 28140,\n",
       " '▁Alfa': 27900,\n",
       " 'wach': 10674,\n",
       " '▁Advance': 18377,\n",
       " '▁Mitte': 16520,\n",
       " '▁overwhelm': 31536,\n",
       " 'oyons': 31964,\n",
       " '▁obsolete': 29451,\n",
       " '▁Morris': 12193,\n",
       " 'bab': 12534,\n",
       " '▁Volunteer': 15740,\n",
       " 'arna': 15918,\n",
       " '▁domenii': 26112,\n",
       " '▁tactics': 15541,\n",
       " '▁terrorist': 10287,\n",
       " '▁judgement': 22555,\n",
       " '▁certainly': 1852,\n",
       " 'boc': 26943,\n",
       " '▁prices': 1596,\n",
       " 'Hence': 13151,\n",
       " '▁sell': 1789,\n",
       " '▁Ble': 11805,\n",
       " '▁incadr': 31120,\n",
       " '▁Chandler': 31154,\n",
       " 'ADI': 27775,\n",
       " '▁linii': 26620,\n",
       " 'abi': 15975,\n",
       " '▁Islam': 10172,\n",
       " '▁Ros': 7963,\n",
       " 'artikel': 23413,\n",
       " '▁Dec': 4451,\n",
       " '▁opus': 26872,\n",
       " '▁Venez': 27889,\n",
       " 'requesting': 22686,\n",
       " '▁Christopher': 14702,\n",
       " '▁Pentagon': 29449,\n",
       " '▁audit': 6572,\n",
       " '▁nützlich': 30001,\n",
       " '▁tradițional': 30304,\n",
       " 'liant': 9333,\n",
       " '▁inevitable': 17508,\n",
       " '▁Theater': 10639,\n",
       " 'ки': 23110,\n",
       " '▁platforms': 5357,\n",
       " '▁1-': 8218,\n",
       " '▁Lead': 12208,\n",
       " 'hopping': 21714,\n",
       " '▁nourri': 24069,\n",
       " '▁souffle': 29108,\n",
       " 'stellen': 5177,\n",
       " 'Adv': 21021,\n",
       " '▁June': 1515,\n",
       " 'installation': 14790,\n",
       " '▁procéder': 30611,\n",
       " '▁PS': 5610,\n",
       " '▁canada': 19343,\n",
       " '▁1971': 17961,\n",
       " '▁dispos': 18815,\n",
       " '▁strange': 6765,\n",
       " 'mode': 14930,\n",
       " '▁bars': 6448,\n",
       " '▁voici': 23646,\n",
       " '▁artisans': 22253,\n",
       " 'Opti': 9546,\n",
       " 'pentru': 23198,\n",
       " '▁Na': 1823,\n",
       " '▁threats': 11262,\n",
       " '▁beverage': 17272,\n",
       " '2)': 7318,\n",
       " '▁Advent': 21333,\n",
       " '▁vegetable': 12065,\n",
       " '▁Researchers': 23066,\n",
       " ').': 137,\n",
       " '▁Post': 1844,\n",
       " 'entraîne': 16293,\n",
       " '▁erkennt': 31988,\n",
       " '▁given': 787,\n",
       " '▁douche': 23568,\n",
       " '▁wages': 15488,\n",
       " 'hour': 5842,\n",
       " '▁Equ': 25262,\n",
       " '▁Balance': 17904,\n",
       " 'Angleterre': 31935,\n",
       " '▁admire': 17728,\n",
       " '▁retro': 9337,\n",
       " '▁Delta': 13057,\n",
       " '▁lucrări': 14325,\n",
       " 'art': 1408,\n",
       " 'iete': 22881,\n",
       " '▁Jardin': 26534,\n",
       " '▁operation': 2986,\n",
       " '▁guard': 4879,\n",
       " '▁decisiv': 24134,\n",
       " '▁ganduri': 30967,\n",
       " 'oara': 12307,\n",
       " 'schutzerklärung': 31291,\n",
       " '<extra_id_77>': 32022,\n",
       " '▁putea': 2574,\n",
       " 'parked': 16669,\n",
       " '▁incearca': 29824,\n",
       " '▁Montpellier': 30817,\n",
       " '▁Wright': 16634,\n",
       " '▁Gift': 8510,\n",
       " 'Fällen': 19730,\n",
       " 'masonry': 30559,\n",
       " '▁spre': 3752,\n",
       " '▁suffered': 8151,\n",
       " '▁climbing': 11908,\n",
       " '▁backup': 7169,\n",
       " 'nstruire': 28457,\n",
       " 'ddington': 30557,\n",
       " '▁travail': 2954,\n",
       " '▁mise': 4705,\n",
       " '▁enough': 631,\n",
       " '▁according': 1315,\n",
       " '▁Training': 4017,\n",
       " '▁vase': 16997,\n",
       " '▁snacks': 12751,\n",
       " '▁india': 18222,\n",
       " 'HU': 17861,\n",
       " 'supported': 29249,\n",
       " '▁Law': 2402,\n",
       " '▁încă': 5646,\n",
       " '▁imminent': 27432,\n",
       " '▁juice': 5143,\n",
       " '▁Records': 11547,\n",
       " '▁electrical': 4850,\n",
       " 'mânt': 27741,\n",
       " '▁introdus': 24762,\n",
       " '▁Person': 5780,\n",
       " '▁gut': 1806,\n",
       " '▁generated': 6126,\n",
       " 'NG': 12531,\n",
       " 'RAC': 22034,\n",
       " '▁Within': 8381,\n",
       " '▁bulbs': 18851,\n",
       " '▁Heidelberg': 30584,\n",
       " 'pal': 6459,\n",
       " '▁Throw': 26191,\n",
       " '▁plate': 3829,\n",
       " '▁Organ': 18190,\n",
       " '▁ieși': 24368,\n",
       " 'allowing': 3232,\n",
       " '▁bal': 6561,\n",
       " 'gian': 22898,\n",
       " '▁excepţi': 30029,\n",
       " 'alia': 5434,\n",
       " '▁attraction': 13715,\n",
       " 'energy': 24310,\n",
       " '▁withdraw': 14510,\n",
       " '▁doute': 12664,\n",
       " 'dass': 20590,\n",
       " 'versicherung': 15587,\n",
       " '▁substantive': 31046,\n",
       " '888': 10927,\n",
       " 'sectiune': 30513,\n",
       " 'jar': 5670,\n",
       " 'се': 22036,\n",
       " '▁nimic': 7362,\n",
       " '▁Betriebs': 14524,\n",
       " '▁conséquent': 27134,\n",
       " '▁rubber': 7859,\n",
       " '▁hockey': 16528,\n",
       " '▁teeth': 3841,\n",
       " '▁Isabel': 25504,\n",
       " '▁norm': 7982,\n",
       " 'drafting': 26797,\n",
       " 'adevar': 22681,\n",
       " '▁acting': 6922,\n",
       " 'avantage': 18986,\n",
       " '146': 24300,\n",
       " '▁prayer': 7029,\n",
       " '▁careful': 6195,\n",
       " '▁electricity': 6373,\n",
       " 'ecția': 26155,\n",
       " '▁Efficiency': 31624,\n",
       " '▁Blockchain': 27037,\n",
       " '▁Produktion': 13930,\n",
       " '▁suflet': 11449,\n",
       " 'limiting': 17979,\n",
       " 'explication': 29734,\n",
       " '▁financiar': 16194,\n",
       " '▁marginal': 18777,\n",
       " '▁Couple': 25185,\n",
       " '▁an': 46,\n",
       " '▁experiencing': 8154,\n",
       " 'provoking': 28268,\n",
       " 'kulturelle': 25739,\n",
       " 'ţilor': 12844,\n",
       " '▁globally': 13448,\n",
       " '▁animation': 9301,\n",
       " '▁Any': 2372,\n",
       " 'accessoire': 29982,\n",
       " '▁fier': 12061,\n",
       " '▁communal': 22393,\n",
       " '▁Raw': 19401,\n",
       " '▁anticipated': 12723,\n",
       " 'reliance': 24638,\n",
       " 'entreprise': 6896,\n",
       " '▁humble': 15084,\n",
       " '▁Bevölkerung': 23749,\n",
       " '▁justify': 18686,\n",
       " '▁Kartoffel': 29402,\n",
       " 'Germain': 31978,\n",
       " '▁expired': 24909,\n",
       " '▁clinician': 21637,\n",
       " '▁Asociaţi': 29116,\n",
       " 'ici': 1294,\n",
       " 'ansprüche': 31485,\n",
       " '▁readiness': 25929,\n",
       " '▁Mall': 13552,\n",
       " '▁infrastructure': 3620,\n",
       " '▁conjug': 26648,\n",
       " '▁Bottom': 23797,\n",
       " 'tourism': 30712,\n",
       " '▁producator': 21492,\n",
       " 'hésitez': 16222,\n",
       " '▁erwarten': 21179,\n",
       " '▁livestock': 22167,\n",
       " 'trakt': 25154,\n",
       " 'ca': 658,\n",
       " '▁desired': 5327,\n",
       " '▁trauma': 11105,\n",
       " '▁Jan': 3049,\n",
       " '▁Bad': 3862,\n",
       " 'since': 27296,\n",
       " 'Severin': 30814,\n",
       " '▁bright': 2756,\n",
       " '▁authorized': 11330,\n",
       " '▁Buddha': 21554,\n",
       " '▁restauration': 28284,\n",
       " '▁inspirational': 18445,\n",
       " 'wöhn': 21575,\n",
       " '▁pounds': 7051,\n",
       " '▁info': 2845,\n",
       " '▁musique': 10497,\n",
       " 'Blue': 22530,\n",
       " '▁Ich': 1674,\n",
       " '▁nu': 206,\n",
       " '▁sheet': 4228,\n",
       " '▁Parent': 17075,\n",
       " 'bread': 20517,\n",
       " '▁pal': 7692,\n",
       " 'phase': 14353,\n",
       " '▁Rac': 23250,\n",
       " 'ра': 7948,\n",
       " '▁plastique': 21865,\n",
       " 'feta': 23414,\n",
       " 'eanu': 9725,\n",
       " '▁brothers': 10740,\n",
       " 'ATH': 24786,\n",
       " 'JC': 20599,\n",
       " 'izare': 5338,\n",
       " '▁releases': 10375,\n",
       " '▁joke': 10802,\n",
       " '▁joining': 6109,\n",
       " '▁euro': 3983,\n",
       " '▁truth': 2827,\n",
       " '▁zones': 10029,\n",
       " '▁1996': 6911,\n",
       " '▁ebay': 22804,\n",
       " '▁renew': 18486,\n",
       " '▁Theory': 18989,\n",
       " '▁icon': 6705,\n",
       " 'arul': 8863,\n",
       " 'dev': 9776,\n",
       " 'LM': 11160,\n",
       " '▁suivre': 14879,\n",
       " 'chat': 16842,\n",
       " '▁preliminary': 17413,\n",
       " '▁Maple': 23153,\n",
       " 'graduate': 17079,\n",
       " '▁precisely': 11185,\n",
       " '▁intimacy': 31249,\n",
       " '▁passed': 2804,\n",
       " '▁bunch': 7292,\n",
       " '▁Mă': 15796,\n",
       " '▁industrial': 2913,\n",
       " '▁porni': 17172,\n",
       " 'versammlung': 24174,\n",
       " '▁Cord': 18217,\n",
       " '▁thermique': 29289,\n",
       " 'Invest': 13898,\n",
       " 'INFO': 29478,\n",
       " 'ités': 8599,\n",
       " 'cra': 2935,\n",
       " 'variété': 26430,\n",
       " '/2016': 24763,\n",
       " '▁lié': 15781,\n",
       " '▁beneficiaz': 25343,\n",
       " '▁charter': 13382,\n",
       " 'notably': 20283,\n",
       " '▁pivot': 16959,\n",
       " '▁vibrant': 8328,\n",
       " '▁Projekte': 16356,\n",
       " 'fibro': 20602,\n",
       " '▁Bay': 2474,\n",
       " '▁Jake': 19806,\n",
       " 'tackling': 26074,\n",
       " '▁fehlen': 21156,\n",
       " '▁consequence': 17009,\n",
       " '▁handmade': 15231,\n",
       " 'lab': 9339,\n",
       " '▁jederzeit': 14544,\n",
       " 'aged': 11438,\n",
       " '▁Ralph': 21171,\n",
       " '▁Ancient': 22239,\n",
       " 'ONU': 28710,\n",
       " 'Help': 29582,\n",
       " '▁und': 64,\n",
       " 'deploying': 29354,\n",
       " '▁conduct': 3498,\n",
       " '▁Reach': 23202,\n",
       " 'RN': 14151,\n",
       " 'élection': 16166,\n",
       " '▁rond': 19033,\n",
       " 'höhe': 22387,\n",
       " '▁Neil': 17906,\n",
       " '▁membres': 9584,\n",
       " '152': 26320,\n",
       " '▁Brilliant': 27159,\n",
       " '▁Bentley': 29262,\n",
       " 'conscious': 25098,\n",
       " '...': 233,\n",
       " '▁inceput': 9985,\n",
       " '▁Constanta': 29850,\n",
       " '▁Überraschung': 30212,\n",
       " 'bald': 8267,\n",
       " '▁motto': 26014,\n",
       " '▁kilogram': 23332,\n",
       " '▁personne': 6317,\n",
       " '▁unfamiliar': 24108,\n",
       " 'story': 13029,\n",
       " '▁influence': 2860,\n",
       " 'they': 11056,\n",
       " '▁Bundes': 6387,\n",
       " '▁Labour': 16117,\n",
       " 'repute': 28285,\n",
       " 'lit': 4250,\n",
       " 'pleade': 30827,\n",
       " '▁Viel': 11779,\n",
       " '▁puterea': 18505,\n",
       " '▁costly': 11855,\n",
       " 'ties': 3010,\n",
       " '▁Massiv': 29973,\n",
       " 'GIN': 24961,\n",
       " '▁To': 304,\n",
       " 'gler': 12683,\n",
       " 'électricité': 24916,\n",
       " '▁freak': 19866,\n",
       " '▁Dennis': 18563,\n",
       " 'interpreting': 29490,\n",
       " ')': 61,\n",
       " '▁Richmond': 17247,\n",
       " '▁abusive': 27031,\n",
       " '▁Panther': 21149,\n",
       " 'brewing': 24702,\n",
       " '▁noastra': 10922,\n",
       " '▁bugetul': 23755,\n",
       " '▁balade': 29164,\n",
       " '▁Properties': 21098,\n",
       " '▁Universität': 16086,\n",
       " '▁blouse': 29273,\n",
       " 'supplemental': 29672,\n",
       " '▁Talk': 7772,\n",
       " 'zehn': 13140,\n",
       " '▁neighbour': 14245,\n",
       " '▁attractive': 5250,\n",
       " '▁Ende': 4925,\n",
       " 'vul': 12388,\n",
       " '▁implied': 19535,\n",
       " '▁organizing': 14308,\n",
       " '2-0': 19423,\n",
       " '▁ignorant': 28617,\n",
       " '▁Kind': 6557,\n",
       " '▁Still': 4886,\n",
       " '▁Rou': 10898,\n",
       " 'derived': 9942,\n",
       " '▁șans': 26931,\n",
       " '▁capacities': 23875,\n",
       " '▁greeting': 18660,\n",
       " 'Box': 16075,\n",
       " 'kämpft': 28875,\n",
       " '▁persoana': 11678,\n",
       " '▁Ceramic': 25457,\n",
       " '▁organizational': 13477,\n",
       " '▁roadmap': 28871,\n",
       " '▁Xiaomi': 27002,\n",
       " '▁observers': 28480,\n",
       " 'elasticity': 31824,\n",
       " 'including': 5751,\n",
       " '▁curl': 18322,\n",
       " '▁volunteering': 21314,\n",
       " 'consuming': 10862,\n",
       " 'Center': 24382,\n",
       " '▁began': 1553,\n",
       " '▁inițial': 31173,\n",
       " '▁centr': 21551,\n",
       " 'http': 5948,\n",
       " '▁lies': 7797,\n",
       " '▁ceux': 6023,\n",
       " '▁tail': 9891,\n",
       " '▁servicii': 8025,\n",
       " '▁Grup': 26319,\n",
       " '▁brake': 9563,\n",
       " 'wordpress': 28234,\n",
       " 'center': 13866,\n",
       " '▁Vegan': 26371,\n",
       " '▁wi': 11064,\n",
       " 'naj': 19906,\n",
       " '▁maple': 22007,\n",
       " '▁со': 24697,\n",
       " '▁courteous': 28490,\n",
       " '▁Delaware': 19722,\n",
       " 'ouette': 24043,\n",
       " '▁drawer': 10326,\n",
       " '▁facade': 27562,\n",
       " '▁drawing': 5364,\n",
       " '▁Wang': 18102,\n",
       " '▁CCTV': 27784,\n",
       " '▁Together': 10965,\n",
       " '▁golden': 7069,\n",
       " '▁por': 5569,\n",
       " '▁extraordinary': 9468,\n",
       " 'pause': 9033,\n",
       " '3.4': 23204,\n",
       " '▁realities': 24684,\n",
       " 'wirk': 22645,\n",
       " '▁Grammy': 26596,\n",
       " 'ular': 4885,\n",
       " '▁Colegi': 27469,\n",
       " '▁compassion': 14555,\n",
       " '▁depression': 7562,\n",
       " '81': 4959,\n",
       " 'war': 2910,\n",
       " '▁acht': 20339,\n",
       " '▁consequent': 21612,\n",
       " '▁illicit': 30234,\n",
       " '▁flight': 3777,\n",
       " '▁Katie': 20413,\n",
       " '▁quoted': 16854,\n",
       " '▁salad': 5870,\n",
       " '▁repeatedly': 16049,\n",
       " '▁Intermediate': 30386,\n",
       " '▁Double': 8405,\n",
       " '▁solidarité': 30897,\n",
       " '▁tumble': 26565,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()\n",
    "# tokenizer(\"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"documents\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"tldr\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e94784416d247569b7c65cd0a1a022a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40607a42980a46939358136ac330fda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 168\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 43\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_tifu = dataset.map(preprocess_function, batched=True)\n",
    "print(tokenized_tifu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_tifu['train']['tldr', 'documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bert_score = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    rouge_res = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    rouge_res[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    results = {k: round(v, 4) for k, v in rouge_res.items()}\n",
    "    \n",
    "    bert_res = bert_score.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    results.update({k: round(v,4) for k, v in bert_res.items()})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d604bb8c02bd4eb595933294c925bb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 7.52 GB, other allocations: 10.46 GB, max allowed: 18.13 GB). Tried to allocate 227.35 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/madisonthantu/Desktop/COMS 6998/Final Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:1582\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1580\u001b[0m     \u001b[39m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1582\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1583\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1584\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1585\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1586\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1587\u001b[0m     )\n\u001b[1;32m   1588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1589\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1894\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:2787\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2786\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2787\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2789\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/accelerate/accelerator.py:1989\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1989\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 7.52 GB, other allocations: 10.46 GB, max allowed: 18.13 GB). Tried to allocate 227.35 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_tifu[\"train\"],\n",
    "    eval_dataset=tokenized_tifu[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 7.75 GB, other allocations: 10.27 GB, max allowed: 18.13 GB). Tried to allocate 240.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/madisonthantu/Desktop/COMS 6998/Final Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:165\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     gen_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_beams\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgeneration_num_beams\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gen_kwargs \u001b[39m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mevaluate(eval_dataset, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:3066\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3063\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3065\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3066\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   3067\u001b[0m     eval_dataloader,\n\u001b[1;32m   3068\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3069\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3070\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3071\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   3072\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   3073\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   3074\u001b[0m )\n\u001b[1;32m   3076\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   3077\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:3255\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3252\u001b[0m         batch_size \u001b[39m=\u001b[39m observed_batch_size\n\u001b[1;32m   3254\u001b[0m \u001b[39m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3255\u001b[0m loss, logits, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys)\n\u001b[1;32m   3256\u001b[0m main_input_name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mmain_input_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3257\u001b[0m inputs_decode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39minclude_inputs_for_metrics \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:293\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    288\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m generation_inputs\n\u001b[1;32m    289\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m generation_inputs\n\u001b[1;32m    290\u001b[0m     \u001b[39mand\u001b[39;00m generation_inputs[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m generation_inputs[\u001b[39m\"\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape\n\u001b[1;32m    291\u001b[0m ):\n\u001b[1;32m    292\u001b[0m     generation_inputs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m--> 293\u001b[0m generated_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgeneration_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgen_kwargs)\n\u001b[1;32m    295\u001b[0m \u001b[39m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgeneration_config\u001b[39m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/generation/utils.py:1496\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1488\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1489\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgeneration results, please set `padding_side=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` when initializing the tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m         )\n\u001b[1;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1494\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m     \u001b[39m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1496\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   1497\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1500\u001b[0m \u001b[39m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/generation/utils.py:661\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    659\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    660\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 661\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoder_kwargs)\n\u001b[1;32m    663\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1123\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1111\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1112\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     )\n\u001b[1;32m   1122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1124\u001b[0m         hidden_states,\n\u001b[1;32m   1125\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1126\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1127\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1128\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1129\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1130\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1131\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1132\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1133\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1134\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1135\u001b[0m     )\n\u001b[1;32m   1137\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:695\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    696\u001b[0m     hidden_states,\n\u001b[1;32m    697\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    698\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    699\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    700\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    701\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    702\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    703\u001b[0m )\n\u001b[1;32m    704\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    705\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:602\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m ):\n\u001b[1;32m    601\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 602\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    603\u001b[0m         normed_hidden_states,\n\u001b[1;32m    604\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    605\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    606\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    607\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    608\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    609\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    612\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:552\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    549\u001b[0m         position_bias \u001b[39m=\u001b[39m position_bias[:, :, \u001b[39m-\u001b[39mhidden_states\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) :, :]\n\u001b[1;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m         position_bias \u001b[39m=\u001b[39m position_bias \u001b[39m+\u001b[39;49m mask  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpruned_heads:\n\u001b[1;32m    555\u001b[0m     mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(position_bias\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 7.75 GB, other allocations: 10.27 GB, max allowed: 18.13 GB). Tried to allocate 240.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit/T5/Gen0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cb55ec8c32461aa5f35c15675c3d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0126f29e3053466ea28997baa0ace993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd881db41bb443c69033afc8d3fca64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/madisonthantu/Desktop/COMS 6998/Final Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tokenized_tifu[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtldr\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m20\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# dataset['test']['documents'][2]\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/Preliminary_Exploration/reddit_dataset_exploration.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset[\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtldr\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m220\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# tokenized_tifu['test']['documents'][2]\n",
    "tokenized_tifu['test']['tldr'][20]\n",
    "# dataset['test']['documents'][2]\n",
    "dataset['test']['tldr'][220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_idxs = np.random.randint(low=0, high=tokenized_tifu['test'].num_rows, size=(5,))\n",
    "sample_idxs = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dict()\n",
    "for idx in sample_idxs:\n",
    "    samples[idx] = {\n",
    "        'document':'summarize: '+dataset['test']['documents'][idx],\n",
    "        'target': dataset['test']['tldr'][idx]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'document': 'summarize: so this happened about an hour ago in first period and it is still haunting me.\\n\\nso to being, about a week ago, my history teacher gives us a group project about world organizations and my group gets unicef. easy enough i think. so the next few days are full of research and such and one of the things i had to research was the unicef corporation in india and central african countries. one of the things that i incorporated was how, on their website, they mention that statutory rape is something that they strongly fight against. so i put that in my slide and move on. fast forward to this morning and my group has to present.\\n\\nwhen my slide comes up, i give my whole schpeel on everything else on the slide and for some reason, i get really nervous when i get to the \"they strongly fight rape\" bullet point. i think that was probably because i had about two more minutes to occupy and saying that they \"strongly fight for statutory rape victims\" wouldn\\'t have taken up that two minutes. so i just start babbling on about how \"rape is bad, mmmkay?\" and i see my friend make a face at me from the other side of the room and, since i was so nervous, i burst out into laughter and i expected him to start laughing with me. but it turns out that he didn\\'t do anything and i just *thought* i saw him make a face. \\n\\nthe worst part of the whole thing was that i couldn\\'t stop laughing and my teacher shot me the nastiest look and asked to see me after class. after that entire thing, i finish my slide and sit back down. then, when the bell rings, i just bolted out of the classroom and here i am, writing this entire thing on my laptop in the lunchroom. reddit, i fucked up bad.',\n",
       "  'target': 'i had a presentation on unicef and how they thought \"rape was bad mmmkay?\" and got nervous while presenting. then i started uncontrollably laughing and my teacher told me to see her after class. instead, i just leave**'},\n",
       " 1: {'document': \"summarize: for most of the walk, i was riding a skateboard and the dog (who is a very large golden retriever) was pulling me like a sled. we started to turn back, and i stopped to mess with the dog's harness while my so went on ahead quite a ways. when i was done, i got on the skateboard and the dog panicked that he wasn't near his owner and began running very fast in order to catch up. either my feet slipped or the dog went slightly to the right, but the skateboard shot out from under me and i got dragged on the side walk for a few inches before i could let go of the leash. a few inches doesn't sound that bad, the whole right half of me is scraped, bleeding , and full of puss.\",\n",
       "  'target': 'dog ran too fast, i got dragged on concrete.'},\n",
       " 2: {'document': 'summarize: this didn\\'t happen today but the thursday just passed.\\n\\ni had just got into work all ready to start (im a supervisor in a convenience store in the u.k.) it was order night so had a busy night ahead of me. a fellow member of the management team answered the shop phone (she was still at work for another 10 mins), and started talking to whoever it was so i decided to go say hi to the staff. \\n\\nshe then left the office and came onto the shop floor with the phone against her ear and went to the tills, picked up the parcel gun (no idea what it\\'s actually called it\\'s just what we use to accept parcels for customers who have them delivered for collection to our store) and started playing with the gun and a parcel, i hear he complaining but have no idea what about and to be honest i didn\\'t really care. \\n\\na couple of minutes pass and i get shouted to the till by the guy serving on there, he handed me the phone and asked if i could sort it out so he could carry on serving, i looked completely confused spoke to the guy on the phone he had no idea why we were ringing him and explained he was from the parcel delivery company and that we had rang there i.t guys, i sure as hell didn\\'t know why so i asked the chap on the till and he had no idea either and told me \"the other manager had just handed him the phone, parcel and parcel gun and told me to sort it\" so i saw kinda a red hue (people who know me know it takes very little to pee me off, which will be explained a later), i went storming around the store to find the other members of staff to find her doing her shopping and choosing what wine she wants to take home (she\\'s still supposed to be at work) i ask her what the issue is and i get \"i left that for (insert name) on the tills to deal with\" that\\'s when i saw a blood red hue. she realised what she had done and tried to explain, but i just turned and walked away.\\n\\nabout 5 mins later me and the guy on the phone get to the bottom of it (a parcel hadn\\'t been scanned as arriving in the shop and the gun thingy wouldn\\'t allow us to do it, so he sorted it) at this point as i\\'m thanking the guy for helping the female worker taps me on the shoulder and tries to explain why she rang them, i look her dead in the eyes and whilst talking to the man say \"i\\'m sorry about that bud, but some members of management have no idea how to work and complete tasks with communication in this store\" turn and walk away.\\n\\nit\\'s about 5 mins later the staff on the till comes upto me and tells me that she started crying when she got to the till and was trying to explain herself in between sobs. i laugh i really couldn\\'t care less (we have never really got on).\\n\\nfriday comes i go into work and the store manager (who has only been there for that week) asks me to step into the office, i\\'m not thick i knew exactly what it was about, he proceeded to throw words around like bullying and inappropriate. i know it was very inappropriate to say especially by the till when there are customers around, and asks for an explanation so he can decide whether or not to take any further action on it. so i explained what had happened (which finds he only then has heard) and that the week before i had just been diagnosed with adult adhd and that my medication hadn\\'t taken effect properly (i even showed him the letter in my personal folder to prove) one of the symptoms my doctor told me were saying/doing things without little thought as to the consequences. \\n\\nhe looks horrified because this is something he missed when going through my folder when he started (and already from doing my research on the company\\'s policy found that they support the staff with this \"mental condition\").\\n\\nso i just escape with a telling off and asked to make sure i try to think things through, she however is now going to loose 1 hours pay and is being interviewed over the incident. so my tifu turned into her tifu.\\n\\n \\n\\nedit:my poor use of paragraphs, thanks to the helpful guys with their guidance',\n",
       "  'target': 'told a member of staff they had no communication skills, made her cry, nearly got disciplined at work, got away with it because i have adhd, now she is possibly getting one instead.'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 191. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "for idx in sample_idxs:\n",
    "    samples[idx]['result'] = summarizer(samples[idx]['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 'summarize: so this happened about an hour ago in first period and it is still haunting me.\\n\\nso to being, about a week ago, my history teacher gives us a group project about world organizations and my group gets unicef. easy enough i think. so the next few days are full of research and such and one of the things i had to research was the unicef corporation in india and central african countries. one of the things that i incorporated was how, on their website, they mention that statutory rape is something that they strongly fight against. so i put that in my slide and move on. fast forward to this morning and my group has to present.\\n\\nwhen my slide comes up, i give my whole schpeel on everything else on the slide and for some reason, i get really nervous when i get to the \"they strongly fight rape\" bullet point. i think that was probably because i had about two more minutes to occupy and saying that they \"strongly fight for statutory rape victims\" wouldn\\'t have taken up that two minutes. so i just start babbling on about how \"rape is bad, mmmkay?\" and i see my friend make a face at me from the other side of the room and, since i was so nervous, i burst out into laughter and i expected him to start laughing with me. but it turns out that he didn\\'t do anything and i just *thought* i saw him make a face. \\n\\nthe worst part of the whole thing was that i couldn\\'t stop laughing and my teacher shot me the nastiest look and asked to see me after class. after that entire thing, i finish my slide and sit back down. then, when the bell rings, i just bolted out of the classroom and here i am, writing this entire thing on my laptop in the lunchroom. reddit, i fucked up bad.',\n",
       " 'target': 'i had a presentation on unicef and how they thought \"rape was bad mmmkay?\" and got nervous while presenting. then i started uncontrollably laughing and my teacher told me to see her after class. instead, i just leave**',\n",
       " 'result': [{'summary_text': 'a week ago, my history teacher gave us a group project about world organizations and my group gets unicef . one of the things i incorporated was how, on their website, they mention that statutory rape is something that they strongly fight against .'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[sample_idxs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'document': 'summarize: so this happened about an hour ago in first period and it is still haunting me.\\n\\nso to being, about a week ago, my history teacher gives us a group project about world organizations and my group gets unicef. easy enough i think. so the next few days are full of research and such and one of the things i had to research was the unicef corporation in india and central african countries. one of the things that i incorporated was how, on their website, they mention that statutory rape is something that they strongly fight against. so i put that in my slide and move on. fast forward to this morning and my group has to present.\\n\\nwhen my slide comes up, i give my whole schpeel on everything else on the slide and for some reason, i get really nervous when i get to the \"they strongly fight rape\" bullet point. i think that was probably because i had about two more minutes to occupy and saying that they \"strongly fight for statutory rape victims\" wouldn\\'t have taken up that two minutes. so i just start babbling on about how \"rape is bad, mmmkay?\" and i see my friend make a face at me from the other side of the room and, since i was so nervous, i burst out into laughter and i expected him to start laughing with me. but it turns out that he didn\\'t do anything and i just *thought* i saw him make a face. \\n\\nthe worst part of the whole thing was that i couldn\\'t stop laughing and my teacher shot me the nastiest look and asked to see me after class. after that entire thing, i finish my slide and sit back down. then, when the bell rings, i just bolted out of the classroom and here i am, writing this entire thing on my laptop in the lunchroom. reddit, i fucked up bad.',\n",
       "  'target': 'i had a presentation on unicef and how they thought \"rape was bad mmmkay?\" and got nervous while presenting. then i started uncontrollably laughing and my teacher told me to see her after class. instead, i just leave**',\n",
       "  'result': [{'summary_text': 'a week ago, my history teacher gave us a group project about world organizations and my group gets unicef . one of the things i incorporated was how, on their website, they mention that statutory rape is something that they strongly fight against .'}]},\n",
       " 1: {'document': \"summarize: for most of the walk, i was riding a skateboard and the dog (who is a very large golden retriever) was pulling me like a sled. we started to turn back, and i stopped to mess with the dog's harness while my so went on ahead quite a ways. when i was done, i got on the skateboard and the dog panicked that he wasn't near his owner and began running very fast in order to catch up. either my feet slipped or the dog went slightly to the right, but the skateboard shot out from under me and i got dragged on the side walk for a few inches before i could let go of the leash. a few inches doesn't sound that bad, the whole right half of me is scraped, bleeding , and full of puss.\",\n",
       "  'target': 'dog ran too fast, i got dragged on concrete.',\n",
       "  'result': [{'summary_text': \"i was riding a skateboard and the dog was pulling me like a sled . the dog panicked that he wasn't near his owner and started running very fast .\"}]},\n",
       " 2: {'document': 'summarize: this didn\\'t happen today but the thursday just passed.\\n\\ni had just got into work all ready to start (im a supervisor in a convenience store in the u.k.) it was order night so had a busy night ahead of me. a fellow member of the management team answered the shop phone (she was still at work for another 10 mins), and started talking to whoever it was so i decided to go say hi to the staff. \\n\\nshe then left the office and came onto the shop floor with the phone against her ear and went to the tills, picked up the parcel gun (no idea what it\\'s actually called it\\'s just what we use to accept parcels for customers who have them delivered for collection to our store) and started playing with the gun and a parcel, i hear he complaining but have no idea what about and to be honest i didn\\'t really care. \\n\\na couple of minutes pass and i get shouted to the till by the guy serving on there, he handed me the phone and asked if i could sort it out so he could carry on serving, i looked completely confused spoke to the guy on the phone he had no idea why we were ringing him and explained he was from the parcel delivery company and that we had rang there i.t guys, i sure as hell didn\\'t know why so i asked the chap on the till and he had no idea either and told me \"the other manager had just handed him the phone, parcel and parcel gun and told me to sort it\" so i saw kinda a red hue (people who know me know it takes very little to pee me off, which will be explained a later), i went storming around the store to find the other members of staff to find her doing her shopping and choosing what wine she wants to take home (she\\'s still supposed to be at work) i ask her what the issue is and i get \"i left that for (insert name) on the tills to deal with\" that\\'s when i saw a blood red hue. she realised what she had done and tried to explain, but i just turned and walked away.\\n\\nabout 5 mins later me and the guy on the phone get to the bottom of it (a parcel hadn\\'t been scanned as arriving in the shop and the gun thingy wouldn\\'t allow us to do it, so he sorted it) at this point as i\\'m thanking the guy for helping the female worker taps me on the shoulder and tries to explain why she rang them, i look her dead in the eyes and whilst talking to the man say \"i\\'m sorry about that bud, but some members of management have no idea how to work and complete tasks with communication in this store\" turn and walk away.\\n\\nit\\'s about 5 mins later the staff on the till comes upto me and tells me that she started crying when she got to the till and was trying to explain herself in between sobs. i laugh i really couldn\\'t care less (we have never really got on).\\n\\nfriday comes i go into work and the store manager (who has only been there for that week) asks me to step into the office, i\\'m not thick i knew exactly what it was about, he proceeded to throw words around like bullying and inappropriate. i know it was very inappropriate to say especially by the till when there are customers around, and asks for an explanation so he can decide whether or not to take any further action on it. so i explained what had happened (which finds he only then has heard) and that the week before i had just been diagnosed with adult adhd and that my medication hadn\\'t taken effect properly (i even showed him the letter in my personal folder to prove) one of the symptoms my doctor told me were saying/doing things without little thought as to the consequences. \\n\\nhe looks horrified because this is something he missed when going through my folder when he started (and already from doing my research on the company\\'s policy found that they support the staff with this \"mental condition\").\\n\\nso i just escape with a telling off and asked to make sure i try to think things through, she however is now going to loose 1 hours pay and is being interviewed over the incident. so my tifu turned into her tifu.\\n\\n \\n\\nedit:my poor use of paragraphs, thanks to the helpful guys with their guidance',\n",
       "  'target': 'told a member of staff they had no communication skills, made her cry, nearly got disciplined at work, got away with it because i have adhd, now she is possibly getting one instead.',\n",
       "  'result': [{'summary_text': \"i'm a supervisor in a convenience store in the u.k. but i didn't really care about it . i went to the tills to find the other members of staff to find her doing her shopping and choosing what wine she wants to take home .\"}]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obligatory this was when i was 9.\\n\\nso it was summer and i live in florida, so when there was a breeze it felt like heaven.\\none of these breezes started in the middle of the day and lasted like 3 hours. \\n\\nthis is where the fuck-up happens.\\nmy dad gets home from work, and we decide to close the window, but little sister wasn\\'t strong enough, so i get sent in.\\n\\n it was stuck; the track on the sides were completely diagonal to where they\\'re supposed to be. i hit the metal sides to try to get it back on track but it doesn\\'t work. \\n\\nso 9 year old me decides \"hey! it would be a good idea to push directly on the glass as hard as possible, right?\" so i do that, and it shatters. my wrists had a deep laceration each, and you could see the tendon in my right wrist.\\n\\n emergency services arrive in 5-9 minutes, and i get some temporary gause for my wrists, and driven to er. have you ever been in the er? if not, imagine antarctica, no joke.\\n\\n so it\\'s 30 degrees in there, and i wait literally 2 hours before anything happens, then the nurse comes in, and injects local anesthetic directly in my lacerations, and at that point i wasn\\'t in shock anymore and my adrenaline was long gone.\\n\\n worst part is, after that, a male nurse looking pissed comes in, without saying anything, grunts, then jams a big ass tetanus shot in my arm. i had to have 7 stitches in each wrist and it took a month and a half for me to recover, had to have my right arm in a splint for that time too.\\n\\npictures + video of me in er:\\n\\nfirst pic [here](https://i.imgur.com/hypfdds.jpg) \\n\\nsecond pic [here ](https://i.imgur.com/r8iy3ih.jpg) \\n\\nvideo (nsfw): [link](https://drive.google.com/open?id=0b29yl7rc8rirvk9gnm8zudber2xqvetwzdj4lvblrkw4zndz)',\n",
       " \"i was like 12 at the time i was home alone and practising a neat trick i had recently learned of throwing snacks into the air and catching them with my open mouth (i'm sure most of you have done or attempted that) anyway i was pretty good with that, my brothers and friends would throw food at me and i'd nail it most of the time.\\n\\nmind you, up until this point id been doing it with cheezels and cheetos.\\n\\nso there i was first one, still remember the colour it was a yellow one. little yellow fucker. up in the air, boom i got this, i should turn pro...  err wrong.  dumb ass. straight down into my wind pipe. oxygen was cut off immediately and i panicked (as you do) it's amazing the amount of stuff that goes through your head in an instant moment like that i remember thinking fuck i can't breathe no ones home what a sucky way to die. you fukn idiot what's mum gonna think. \\n\\ni hopped around for a few seconds trying to figure out what to do my mind was racing but i knew not to inhale it deeper. i considering doing a hymlec on myself by running backwards into the wall but i eventually coughed really hard and it came flying out i still remember it in slow motion it flew up and across about a metre or two and hit the wall in front of me. fell to the floor. oxygen. raced back in. \\n\\ni remember thinking fuck i almost died cos of a peanut m&m. i never told my parents cos i was too scared.\\n\\ni'd told my daughter this story and warned her to never do it.\\n\\nstupid fucking kids. \\n\\never since whenever i've read about people dying in really stupid ways like that a part of me is super compassionate because i know it could of happened to me.\",\n",
       " 'okay, i apologize in advance for any mistakes as english is not my first language, so here\\'s a small introduction. this happened around 26 hours ago by the time of writing: \\n\\nover the course of a few months back, one of the two coolers of my gpu (an amd r9 270) began emitting some weird noise, i figured it was no big deal, and let it be. some time later, the noise worsened and became almost impossible to ignore, i gave it a quick check and concluded that the fan was simply scratching the cooler\\'s armor due to being ever so slightly slanted / off center, and as there was nothing i could do about it, i closed my computer and went on with my life, ignoring my gpu\\'s pleas for help, after some small while, this fan would then sometimes stop working altogether until re-centered and, later on, broke completely of its slot.\\nheeding my own mistakes from the past as the same process began with the second, and last cooler, i realized there was no option other than taking matters in my own hands, since it was becoming rather boring having to crouch to my tower from time to time to correct the fan\\'s center and it\\'s warranty was long gone.\\n\\ni decided to open my gpu myself and superglue the first fan\\'s pin to the center pin of its original slot, taking my time and being extra careful as to not glue the stator and rotor, all goes well and i give it a shot.\\n\\nhere\\'s the fu:\\nafter turning my computer back on, i noticed that it was constantly scratching the armor and generating a pretty loud noise, thus, i think: \"hey, it\\'s probably the same thing from the other one, i just have to slowly stop it by holding the center of the fan, and then push slightly so it clicks back into position, no big deal\".\\nbeing the gigantic dumb ass i am, i accidentaly missed the center and touched one of the fan\\'s blades, this made it go from god-knows-how-many-rpm to 0 instantly, suddenly breaking the pin again and throwing all my work through the window, leaving the fan not working again and glued to it\\'s position, meaning i can\\'t simply redo the process without breaking it even further.\\nas it was quite late when it happened (around 02:00 am), i simply decided to turn off my computer and go to sleep, little did i know that i was only going to get out of my bed 20 hours later, greatly ashamed of my stupidity.',\n",
       " \"title, literally never used this sub so apologies if something i'm writing here isn't right. \\nanyways, today i received a refund deposit check in the mail from at&t since i've been with them for a year now. at first i actually thought the check was a bill to be honest, i have no credit history so that's why i needed to put the deposit down in the first place. anyways, the actual tearing part of this happened when i had successfully removed the check from the rest of its carefully perforated paper surrounding. i was so excited to get my $500 back, i decided to shred the excess paper in half as i do with all junk mail or mail i've already read and don't need. \\n\\nthe check was still in my _hands_ when i tore the excess paper. \\n\\nso now i've got two halves a $500 deposit. i've posted on an at&t help forum for some direction on who to call so i can hopefully skip a 30minute wait time in their phone system.\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tifu['train']['documents'][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "def perform_summarization(sample):\n",
    "    inputs = [prefix + doc for doc in sample[\"documents\"]]\n",
    "    return summarizer(inputs, max_length=30)[0]\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=output_dir)\n",
    "\n",
    "res_dataset = concatenate_datasets([dataset[k] for k in dataset.column_names])\n",
    "# res_dataset\n",
    "# 'summarize: so\n",
    "\n",
    "summaries = res_dataset.map(perform_summarization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary_text': 'i bought myself a cone full of ice cream just before we drove off . the one hand holding my glasses smacked'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = perform_summarization(res_dataset[0:3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = summarizer(res_dataset['documents'], max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'i bought myself a cone full of ice cream just before we drove off . the one hand holding my glasses smacked'},\n",
       " {'summary_text': 'friend 2 actively encouraged me and i did two large shots . after doing some random shit, i kind of passed out and'},\n",
       " {'summary_text': 'i was so terrified that i woke up extra early so i could get to work before anyone and avoid the awkward af'},\n",
       " {'summary_text': 'i went to a nice restaurant known for all of its baseball memorabilia and this was also a kind of sales team dinner'},\n",
       " {'summary_text': \"i was trying to open a heat sealed packet of cilantro by hand so i figured i'd use my knife .\"},\n",
       " {'summary_text': \"i always brought root beer to drink, we were kids, so didn't get the whole water thing, and this was long before \"},\n",
       " {'summary_text': 'jcl has the most financial assets and is the biggest of any club on campus . the club has so much money, we get'},\n",
       " {'summary_text': \"i'm just a logistics guy, but i am not an a/v guy. i started to feel woo\"},\n",
       " {'summary_text': \"i'm a 20 year old dutchman, but i have never seen so many angry middle fingers and honkers\"},\n",
       " {'summary_text': \"i'm blacked out hammered. i sat around waiting to see if she was going to hit\"},\n",
       " {'summary_text': 'the government was experimenting with granting students free laptops with fully updated software and programs for educational purposes . one of my friends discovered that'},\n",
       " {'summary_text': 'i was tripping balls and hallucinating and decided to get myself checked out at the a&e and had a'},\n",
       " {'summary_text': 'the final project for my theatre class was a 20 page paper based on 30 questions . many of the questions were about ourselves, and'},\n",
       " {'summary_text': '2 friends and i went away for a bit of a boys weekend to watch a big game of cricket in the cricket world cup'},\n",
       " {'summary_text': 'in may i started my summer internship/job as a teller for a bank . the bank reopened 12 hours from'},\n",
       " {'summary_text': 'dachsund (peaches) came upstairs and was moaning and whining and then was unable to move her back legs'},\n",
       " {'summary_text': \"i worked at a butcher's during the weekend, where we would clean everything (floor, walls, machines) with high-\"},\n",
       " {'summary_text': \"i just blew up the microwave. not a little ' oh, the sides of this tv dinner lasagna\"},\n",
       " {'summary_text': 'i was a recovering anorexic and i know how hard it is, especially when one is so underweight . she'},\n",
       " {'summary_text': \"i've been undergoing a lot of stress as i have some very important end of year exams coming up . i\"},\n",
       " {'summary_text': 'reddit is like on strike. so all the subs i visit are closed. so naturally i try to be productive and go'},\n",
       " {'summary_text': \"i woke up with diarrhea and stomacheaches. i'm laying in bed and decide to watch tv being that\"},\n",
       " {'summary_text': 'i have been in a clan in the online game world of tanks for 357 days . my first mistake was dicking around'},\n",
       " {'summary_text': 'i realized my gf was supposed to be at work... but she was looking for propel water...i desperately was trying to wake her'},\n",
       " {'summary_text': \"i received a deposit check in the mail from at&t since i've been with them for a year now .\"},\n",
       " {'summary_text': 'i grabbed my trusty bottle of bleach and started spraying the whole thing down . the 3-tier center thing has a little'},\n",
       " {'summary_text': 'i bought tickets to sydney to watch her swim in the nationals competition . my girlfriend is a freak at swimming'},\n",
       " {'summary_text': \"i'm on the brink of breaking down, and have to wait another 20 minutes or so to get to my flight . \"},\n",
       " {'summary_text': \"she doesn't want a big party with friends, too much attention, etc. says she only wants to spend it with me .\"},\n",
       " {'summary_text': 'in nz at the time the minimum wage was $13.50 per hour . i showed him this post and enjoyed reading it out'},\n",
       " {'summary_text': \"i was 16 at the time, and was studying for my gcse's . my parents were making me stay in\"},\n",
       " {'summary_text': \"my wife and i took a circle tour of the island and went to 'turtle beach' they were given explicit instructions that\"},\n",
       " {'summary_text': 'oklahoma state university student slammed a line of cars that wrapped all the way out our lot and down the'},\n",
       " {'summary_text': \"i wake up the next day, go to the bathroom to take a piss, look down and i'm faced with\"},\n",
       " {'summary_text': 'i grew up in germany where i went to a german secondary school that went from 5th to 13th grade .'},\n",
       " {'summary_text': 'i spent the night in county jail for being an idiot . my wife, who thought i was in bed, woke up to'},\n",
       " {'summary_text': \"my girlfriend and i are currently on our gap year before university . i've been coming over quite often . she's\"},\n",
       " {'summary_text': 'i live in ne iowa and mother nature released 6-ish inches of snow upon us wednesday . '},\n",
       " {'summary_text': \"i forgot to confirm with the subject before i sent it in . so there's information out there that's not supposed to\"},\n",
       " {'summary_text': \"i was really fucking embarrassed and i didn't handle embarrassing moment well as a 9 year old . the show\"},\n",
       " {'summary_text': 'i learned how to sleep in this class very quickly, since its better than skipping and sometimes i would try to listen . the'},\n",
       " {'summary_text': 'my boyfriend, austin, works out of town quite a bit . he had to leave at 4am the day after '},\n",
       " {'summary_text': \"i'm corn-holing here trying to hold in each pain to not just go ahead and shit all over everyone there.\"},\n",
       " {'summary_text': 'i was just like \"oh god\" her face changed immediately as her question trailed off into awkwardness and we both solem'},\n",
       " {'summary_text': \"i've donated blood to the hong kong red cross for the second year in a row . it was a fri\"},\n",
       " {'summary_text': 'i went to the ladies’ room to wash my face, sprinkled a lot of water on my white silk shirt, and it got'},\n",
       " {'summary_text': \"a month and a half ago, i was at my friend's after a long day of work, relaxing, drinking be\"},\n",
       " {'summary_text': \"i woke up and had a shit ton of blood on my pillow and i couldn't hear anything out of\"},\n",
       " {'summary_text': 'i got into cryptocurrency trading a few weeks ago and it became like an addiction . every few minutes i have the urge to check'},\n",
       " {'summary_text': 'my buddy and his girlfriend have been having problems for the past few months, over the last month they have split and gotten back together a'},\n",
       " {'summary_text': \"i'm a pretty polite guy so i don't really bring it up unless she brings it up. she doesn\"},\n",
       " {'summary_text': 'i go to a class where the lecturer asks me to wait while they try to get ahold of my lecturer '},\n",
       " {'summary_text': \"i've been naked in front of my window dozens of times, no one has ever been close enough to see me in any detail\"},\n",
       " {'summary_text': \"this happened at my cousin's graduation party last saturday . i was high as fuck, so i went\"},\n",
       " {'summary_text': \"i thought they wouldn't understand what i said. now i'm gonna see them all tomorrow in class and it'\"},\n",
       " {'summary_text': \"i'm in full blown panic mode but too weak to do anything other than strip off my clothes . my roommate has gone\"},\n",
       " {'summary_text': 'a team of student is going to work with us on an app for their course . we created chatrooms on whatsapp to'},\n",
       " {'summary_text': \"i've played for about a week and i saved up 10,000 souls before i got into blighttown .\"},\n",
       " {'summary_text': 'i put on my headphones and tried to get comfortable before putting on a >40 min clip on /r/gonewildaudio'},\n",
       " {'summary_text': \"i work at a coffee place, so naturally, i don't mind since i like the quietness. today i\"},\n",
       " {'summary_text': 'the irony of the situation hit me and i stopped walking . there i was about to sell a bunch of pens,'},\n",
       " {'summary_text': \"thanksgiving day, last year, we are at a friend's remote mountain house outside of san jose . i\"},\n",
       " {'summary_text': 'i was given an assignment to work on along with the rest of my group of students . i had to be very precise in my'},\n",
       " {'summary_text': 'i screamed \"what the fuck\" on the top of my lungs and jerked my hand back,'},\n",
       " {'summary_text': \"i was seventeen when this happened. i'm fine now and all wounds have healed up . my friend and i were\"},\n",
       " {'summary_text': \"i'm so used to deposit my checks with mobile deposit and having it go through, that i didn't even wait for the\"},\n",
       " {'summary_text': \"i was working at a gourmet chocolate store, lindt, on valentine's day . i fucked\"},\n",
       " {'summary_text': \"i was nailed to the ground with all that stuff lying on me and i couldn't move. had to straighten the\"},\n",
       " {'summary_text': 'i went to costco and bought a huge tent that was large enough for all 10 cub scouts to sleep in'},\n",
       " {'summary_text': \"i'm in high school and take agriculture classes, but i didn't realize my fuck-up . i\"},\n",
       " {'summary_text': 'tifu bad followed reddit advice. looked at me as if i was a turd stuck on the toilet'},\n",
       " {'summary_text': 'parents are visiting from out of town for the holidays . i grab the plastic bag out of the trash can and walk out past them again'},\n",
       " {'summary_text': 'i am a top 100 erotica writer on amazon, i write and publish my own stories . my wife and '},\n",
       " {'summary_text': 'i was bullies often for being a small nerdy looking white kid . i got beat up by 3 black girls'},\n",
       " {'summary_text': \"i'm a living tifu i got online at the pokémon online thing and was engaged to trade \"},\n",
       " {'summary_text': \"i'm working on replacing a tote of bleach that is used for treating our cooling water . when i get my\"},\n",
       " {'summary_text': 'an amd r9 270 fan was scratching the armor and causing a pretty loud noise . i decided to open'},\n",
       " {'summary_text': \"i'm a supervisor in a convenience store in the u.k., but i didn't really care \"},\n",
       " {'summary_text': 'alicia smoked weed, drinking way too much wine and laughing, it was just me and my friend in till this guy and his'},\n",
       " {'summary_text': 'i forgot to lock the door, and my sister opens it, sees me on the toilet, slams the door on'},\n",
       " {'summary_text': 'i mapquest the strib club a few towns over, print them directions out, throw on my sweatpants, grab'},\n",
       " {'summary_text': 'the seadoo stalls out after running for a few minutes, so we decided to jump it with the truck and drive it'},\n",
       " {'summary_text': 'jay and his father are on the way, so we have a joke about \"sexy dads\" jay says he'},\n",
       " {'summary_text': \"'07 cobalt is a fast back with a spoiler, which means you can't see a damn thing out\"},\n",
       " {'summary_text': \"i keep the doors of my car locked when i'm driving around because of obvious reasons . but a few days ago,\"},\n",
       " {'summary_text': 'i had a great idea that a few people can sleep at the sauna because it has enough space to fit around 10 people if'},\n",
       " {'summary_text': 'i left the living room for a drink from the kitchen and my dad was sitting in there with my brother and i just hear\"'},\n",
       " {'summary_text': 'i was going to do homework on my laptop and watch netflix but, due to the aforementioned procrastination'},\n",
       " {'summary_text': \"i have full trust in louise and i know she didnt intentionally run away from home. i'm just gonna\"},\n",
       " {'summary_text': 'after 3 years i finally got the boss to buy us a new whiteboard . i work in a dive center and we'},\n",
       " {'summary_text': \"i'm walking home from an honest, hard day at work and a difficult day at therapy . i see a neighbor\"},\n",
       " {'summary_text': 'i found an abandoned flash drive in the dorm computer lab and returned it to a girl who happened to be one of the '},\n",
       " {'summary_text': 'warning! poop involved in story. i had a breast reduction three days ago. surgery went well, was put under ane'},\n",
       " {'summary_text': \"the manhole cover in most streets is something you never pay attention to . it's an item of no value or no apparent need of\"},\n",
       " {'summary_text': 'i was diagnosed with severe adhd and mild dyslexia as a child . my documented diagnosis could bring into questioning by legal'},\n",
       " {'summary_text': 'i went to private school from 4th grade until this happened my junior year of high school . my parents were not mad at me at'},\n",
       " {'summary_text': '\"kaylee\" is a sci-fi character, and i am of average looks, not at all athletic, mildly'},\n",
       " {'summary_text': 'when black ops 3 and rainbow 6 siege launched for the xbox one, i just had to get it . i'},\n",
       " {'summary_text': \"i'm a performer of sorts and recently got hired for my first gig in a long while . on satur\"},\n",
       " {'summary_text': 'i was like, \"nice, good eyes\"... then i look down at her again and realize it wasn\\'t just a'},\n",
       " {'summary_text': \"i just moved to a new city and i am currently a sophomore in high school . so let's start this.\"},\n",
       " {'summary_text': 'one egg rolled under the kitchen shelves we had, slightly cracked but not leaking... now, i should probably explain that i live'},\n",
       " {'summary_text': 'i was having a pretty bad day, and was tired because of it . i decided to projectile piss into my'},\n",
       " {'summary_text': 'i woke up this morning to find that i missed my first class and had a test in an hour, i immediately '},\n",
       " {'summary_text': \"i haven't done wash in about a week and just decided to throw on some clothes that were on my floor . my\"},\n",
       " {'summary_text': 'i started feeling unusually drunk and have to go to the bathroom . i blacked out and fell asleep in the floor on'},\n",
       " {'summary_text': 'russian grandma mutters something in russia which i hope means \"it\\'s ok\" but she curse'},\n",
       " {'summary_text': 'i accidentally leaked a small amount on my underwear when i was 12 . i jumped in the shower and '},\n",
       " {'summary_text': 'a week ago, my history teacher gave us a group project about world organizations and my group gets unicef . one of the'},\n",
       " {'summary_text': 'i wanted to look good for the interview so i shaved my face and gave my self a haircut . i'},\n",
       " {'summary_text': 'my brother, adam, was 9 years old when he was 12 years old . he threw a chair across'},\n",
       " {'summary_text': \"i have a date with the girl tonight, and i don't know how much longer i can keep this up .\"},\n",
       " {'summary_text': 'i have been addicted to this subreddit for a few weeks, but i decided i would contribute . i'},\n",
       " {'summary_text': \"a couple days ago i was at trader joe's to end my 2 week toast and peanut butter diet . \"},\n",
       " {'summary_text': 'i had a motocross accident, broke my arm and collarbone, both on the same side, my arms in a cast'},\n",
       " {'summary_text': 'i went to the dominican republic three or four months ago . my family and i saw how nice the employees were and how'},\n",
       " {'summary_text': \"i was so scared and couldn't stop my stomach convulsions, so i just sat in the shower and dealt\"},\n",
       " {'summary_text': 'i just joined reddit and i am posting it now . my crush got off the school bus to walk to school .'},\n",
       " {'summary_text': \"i grew up using my dad's camera, then finally bought my own when i was 13 . 2 weeks ago i\"},\n",
       " {'summary_text': 'i work for an ambulance company and we drive the chevy van type . my partner woke up and mumbled \"'},\n",
       " {'summary_text': 'i was nineteen, in college, and dating this incredible woman, selma hayek . she was hispan'},\n",
       " {'summary_text': 'i went downstairs to light a candle and hang with my sister . i frantically tried to get to the window to open'},\n",
       " {'summary_text': \"i'm sitting on the bathroom floor with a hot compress over my left eye . i have a bad habit of not\"},\n",
       " {'summary_text': \"i work at reception so i'm seated at the front desk . i see this man in a wheelchair approaching the\"},\n",
       " {'summary_text': \"i'm working from home lately, which gives me a bit of a more lax routine in the morning . i\"},\n",
       " {'summary_text': 'i felt like a total badass and only nailed it just once, but god damn did i feel like '},\n",
       " {'summary_text': 'i gave my ipad to my ex when we were still together, we broke up about 6 months ago . so just recently '},\n",
       " {'summary_text': \"i'm a smart man, i will macgyver the fuck out of this shit. i\"},\n",
       " {'summary_text': 'i lost my job, nor did we lose the client over possibly unrelated issues . i had made some unusual technology decisions in building'},\n",
       " {'summary_text': \"my sister is 18, i'm 30 and we never pass an opportunity to scare one another . i crouch down and\"},\n",
       " {'summary_text': 'i often hold my controller just above my knees, and this often leaves my arms close to my legs/hip . because of my'},\n",
       " {'summary_text': 'i got fed up after what seemed like an eternity of failed attempts in unlocking my door . i found the home phone, and'},\n",
       " {'summary_text': 'scooter is a double-headed maraca that definitely looks like a dick . it was literally loud as fuck'},\n",
       " {'summary_text': 'i flipped out, threw open my car door, and gave the car parked next to me a new paint finish on'},\n",
       " {'summary_text': 'i heard an odd screech coming from the open bathroom which is right outside of my bedroom . i stood there laughing until '},\n",
       " {'summary_text': 'i was riding a skateboard and the dog was pulling me like a sled . the dog panicked that he'},\n",
       " {'summary_text': 'i was bleeding profusely at 6am, and trying to wrap anything on this to control the bleeding. i get 7 stitches in'},\n",
       " {'summary_text': \"i'm a tinder fan, but i don't know how to describe it, but that's what it\"},\n",
       " {'summary_text': 'the cashier came up to me and said something which, in my inability to pay attention, i did not understand at all .'},\n",
       " {'summary_text': \"i've never been pulled over for anything more than a headlight being out . i had 7 eye surgeries before i\"},\n",
       " {'summary_text': 'after 2 hours i start to feel very bad, so i decide to go to the toilet. wash my hands. everything is ready,'},\n",
       " {'summary_text': \"i used the shampoo daily, but now i'm starting to get an itchy feeling on me dear plums . my\"},\n",
       " {'summary_text': 'i get a text from the organizer saying we are short one because someone is too hungover to play . my buddy, who'},\n",
       " {'summary_text': 'in the netherlands, people are usually **11-13 years old in their first year of high school** . a friend of mine'},\n",
       " {'summary_text': 'i thought it would be funny to tape everything in my girlfriends room to the ceiling of her room . my friend helped me get everything'},\n",
       " {'summary_text': 'dancing with no dick restriction is a good idea for all of you who think dancing with a psa can be '},\n",
       " {'summary_text': \"the nozzle was plugged since it hadn't been used in a long time . i walked out of the bathroom to\"},\n",
       " {'summary_text': 'i live in florida, so when i was 9 it felt like heaven . i hit the metal sides to try to'},\n",
       " {'summary_text': 'i started furiously scrubbing the desk with lysol wipes, gagging as i went since like '},\n",
       " {'summary_text': \"i picked my oldest kayak, an 8' fishing kayak i haven't used in a while . when i lifted\"},\n",
       " {'summary_text': \"i am a college junior and am in a business communications course which is probably the most time consuming class i've taken\"},\n",
       " {'summary_text': 'i went to six flags (amusement park) for senior day with my physics class . she asked to use my iphone so'},\n",
       " {'summary_text': 'i accidentally sucked in a load of lava-ish temperature hot chocolate and burnt my mouth and throat . i'},\n",
       " {'summary_text': 'my boyfriend and i have always maintained a great sex life, i mean, really fucking great . '},\n",
       " {'summary_text': 'i was 15 when i shot my new airsoft gun a week ago . i jumped up from my chair and said'},\n",
       " {'summary_text': 'i was ecstatic! i thanked him a million times and basically felt blessed. so flash forward to the harbor,'},\n",
       " {'summary_text': 'i used to have a friend, and we played in the lowest league (iron) together . i checked his steam profile to'},\n",
       " {'summary_text': \"i have insomnia. it's not my first language. it 'came' once in a month where the longest i\"},\n",
       " {'summary_text': \"i am currently a junior in college, living off campus for the first time with 2 of my mates . i'm\"},\n",
       " {'summary_text': 'after a few hours, i mentally calculated how much money i was up or down in the last 5 and 10 pulls .'},\n",
       " {'summary_text': 'i made a new friend a little bit ago, and we grew close pretty quickly . sarah asked me who'},\n",
       " {'summary_text': 'i felt a bit of excitement in me when i realized she was in my math class this quarter again . i decided to'},\n",
       " {'summary_text': \"my fiancée's best friend held her 30th birthday party on saturday night . she was fucking\"},\n",
       " {'summary_text': 'brining is where you soak the whole bird in a bath of salt water . my wife and i had decided to try brining'},\n",
       " {'summary_text': \"i'm still sitting on my throne pondering about this, so i guess for once it did happen today\"},\n",
       " {'summary_text': 'i was about to drop them off and i saw the battery light came on . my mother and sister wanted to see a relative'},\n",
       " {'summary_text': 'i have always been one of those lucky people who throw food together and it ends up marvelously . when i try a new'},\n",
       " {'summary_text': 'i was working with a gentleman interested in a 2014 2500hd, brand new . the company put out 24 months/2'},\n",
       " {'summary_text': 'maxtor hdds could refuse to work on new hardware, especially new psus . after plugging it into'},\n",
       " {'summary_text': 'i am by no means a writer, so forgive my spelling and grammatical errors and join me on this tale of f'},\n",
       " {'summary_text': \"i yell to the bedroom where my gf is watching tv. she blurts out that she'll look\"},\n",
       " {'summary_text': 'fraud prevention red flagged a shipment order for about $4,000+ worth of iphones . i had a plethora'},\n",
       " {'summary_text': \"i was a freshman in high school and i didn't figure out whether the damn cover was plastic or plastic so i lifted\"},\n",
       " {'summary_text': 'i had my own room when most people had to share with 3 or 4 other people . when it came time to move out at the'},\n",
       " {'summary_text': \"a class trip to italy, it was ordinary for us to get drunk daily . one of them didn't two s\"},\n",
       " {'summary_text': 'i was having so much fun online that i let myself jump the curfew and actually slept at 5am . '},\n",
       " {'summary_text': 'a yearly tenant party is going on outside in my apartment building . i spilled detergent on my laundry bag and i'},\n",
       " {'summary_text': \"i always take him with me in the car (he doesn't like being alone) i open the car door for him and point\"},\n",
       " {'summary_text': 'running is a very common hobby where i live so i am not used to people looking twice at me . the combination of thin'},\n",
       " {'summary_text': 'i remember thinking fuck i almost died cos of a peanut m&m. i never told my parents co'},\n",
       " {'summary_text': 'the last time we texted, i got a sense she was going through something . when she mentioned she was having a drink'},\n",
       " {'summary_text': 'a scion iq tire came in two days later, so they could put the new tire on the old rim .'},\n",
       " {'summary_text': \"i've never started a fight, and when i fought i have always been respectful to my opponents if i\"},\n",
       " {'summary_text': 'i jumped off my feet and fell on my butt in front of my entire school . i was fine physically, but internally'},\n",
       " {'summary_text': 'my friend hit me up to come up for their end of the year date party/banquet . i conscripted my'},\n",
       " {'summary_text': 'shilliam and i decided it would be funny to interrupt their make out session by doing stupid shit in front of them'},\n",
       " {'summary_text': 'i woke up this morning, grabbed my phone and sent her a little \"have a good start to your week!\"'},\n",
       " {'summary_text': 'i decided to ride the bus to the end of the line, and find my bike amidst a throng of parked'},\n",
       " {'summary_text': \"i'm lying on the ground writhing in intense pain for a few minutes while many obscenities fill the air \"},\n",
       " {'summary_text': 'i fucked up by getting high and shaving my scrote. now i know what happens when you get morning wood with'},\n",
       " {'summary_text': '18 year old dude in sydney is required by law to use an adult pass for public transport . he hits me'},\n",
       " {'summary_text': 'i shaved my head every other day, so through my itching in my sleep, i managed to spread it to the'},\n",
       " {'summary_text': 'i got a $50 card, a $10, and a card for the xenoblade 2 expansion pass .'},\n",
       " {'summary_text': 'eclair, my siamese cat, is very vocal and likes to sleep all day [though not on my lap... she'},\n",
       " {'summary_text': \"i've been married to my wife for seven years . i have two kids under three, which is 50% awesome and 50% sleep\"},\n",
       " {'summary_text': 'l was told that l may be getting a after school detention for sending \"u wot m8\" to the whole'},\n",
       " {'summary_text': \"mexican food chain is notorious for giving people digestive problems, but that's not why we eat it do we :)\"},\n",
       " {'summary_text': 'i enlisted the kids to help grab the groceries and load them into the car . monday rolls around and i take the'},\n",
       " {'summary_text': 'the fuckup happened about 10 minutes ago in seattle . i type \"dicks\" into my computer on google images'},\n",
       " {'summary_text': \"the gf is still googling symptoms and think it's bowel cancer . edit: dont worry i dont have\"},\n",
       " {'summary_text': 'i woke up almost mid piss with my shirt, boxers, and sheet completely soaked . when i get back'},\n",
       " {'summary_text': 'i am transgender and i look and sound like a bloke, so i have to wear a bra '},\n",
       " {'summary_text': 'my chain will randomly lock itself, then continue going every like ten minutes . my cousin is coming in tomorrow and he works on bikes'},\n",
       " {'summary_text': 'i went to the local bar for the first time since the break up . she was always the submissive type, but this night'},\n",
       " {'summary_text': \"me and my bro skipped school because my mom wouldn't be home all day (getting her massage license renewed) but came home with\"},\n",
       " {'summary_text': 'i have had a full week at work where we have been super slammed...so, i am late posting'},\n",
       " {'summary_text': 'i went into a lab to do a urinalysis for a new job . after about a twenty-'},\n",
       " {'summary_text': 'i had travelled to an out-of-town netball tournament with my friends, and were stuck in the middle of the first day'},\n",
       " {'summary_text': 'i slammed into heelie shoes knocking him down onto his side, which broke his left arm at the wrist '},\n",
       " {'summary_text': 'i lent my friend one of my guitar picks, and at the end of class she came to give it back . instead of'},\n",
       " {'summary_text': 'i was tripping on how my pen presses down on the paper and leaves a trail of ink . i had'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
