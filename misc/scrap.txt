python run_summarization_gpt2.py \
    --model_name_or_path gpt2 \
    --do_train 1 \
    --do_eval 1 \
    --do_predict 1 \
    --train_file initial_datasets_dialogue_gpt_gen0_test_data.csv \
    --validation_file initial_datasets_dialogue_gpt_gen0_test_data.csv \
    --test_file initial_datasets_dialogue_gpt_gen0_test_data.csv \
    --num_epochs 1 \
    --output_dir initial_datasets_dialogue_gpt2_gen0_test_data \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --gen_num 0 \
    --dataset_name dialogue \
    --base_model gpt2 \
    --overwrite_cache 1 \
    --overwrite_output_dir 1 \
    --DEBUG 1

python run_summarization_gpt2.py \
    --model_name_or_path results/experiment1/dialogue/gpt2/gen0 \
    --do_predict 1 \
    --test_file initial_datasets_dialogue_gpt_gen0_test_data.csv \
    --num_epochs 1 \
    --output_dir results/experiment1/dialogue/gpt2/gen0 \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --gen_num 0 \
    --dataset_name dialogue \
    --base_model gpt2 \
    --DEBUG 0


python run_summarization_gpt2.py \
    --model_name_or_path gpt2 \
    --do_predict 1 \
    --test_file initial_datasets_dialogue_gpt_gen0_test_data.csv \
    --num_epochs 1 \
    --output_dir results/experiment1/dialogue/gpt2/gen0 \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --gen_num 0 \
    --dataset_name dialogue \
    --base_model gpt2 \
    --DEBUG 0

python run_summarization_gpt2.py \
    --model_name_or_path results/experiment1/reddit/gpt2/gen0 \
    --do_predict 1 \
    --test_file initial_datasets_reddit_gpt_gen0_test_data.csv \
    --num_epochs 1 \
    --output_dir test__reddit_gpt2_gen0 \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --gen_num 0 \
    --dataset_name reddit \
    --base_model gpt2 \
    --DEBUG 0

python run_summarization.py \
    --model_name_or_path t5-base \
    --do_predict 1 \
    --test_file initial_datasets_reddit_t5_gen0_test_data.csv \
    --num_epochs 1 \
    --output_dir test__reddit_t5_gen0 \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --gen_num 0 \
    --dataset_name reddit \
    --base_model t5 \
    --DEBUG 0

python run_summarization_gpt2.py \
    --model_name_or_path results/experiment1/reddit/gpt2/gen1 \
    --do_eval 1 \
    --do_predict 1 \
    --validation_file synthetic_datasets_reddit_gpt_gen1_test_data.csv \
    --num_epochs 1 \
    --output_dir test_synthetic_datasets_reddit_gpt2_gen1 \
    --per_device_train_batch_size=1 \
    --per_device_eval_batch_size=1 \
    --gen_num 1 \
    --dataset_name reddit \
    --base_model gpt2 \
    --overwrite_cache 1 \
    --DEBUG 0