{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.1-arm64-arm-64bit\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/hcy50x855gvf2b1qwkjstnvh0000gn/T/ipykernel_40769/878238529.py:14: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  print(torch.has_mps)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(platform.platform())\n",
    "print(torch.has_mps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFs:**\n",
    "- https://huggingface.co/docs/transformers/tasks/summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit/T5/Gen0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "dataset_name = 'reddit'\n",
    "model = 'T5'\n",
    "generation = 'Gen0'\n",
    "output_dir=os.path.join(dataset_name, model, generation)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifu = load_dataset(\"reddit_tifu\", 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tifu = tifu.add_column\n",
    "doc_sent_len = [len(re.findall(r'\\w+', sentence)) for sentence in tifu['train']['documents']]\n",
    "summ_sent_len = [len(re.findall(r'\\w+', sentence)) for sentence in tifu['train']['tldr']]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, tight_layout=True)\n",
    "\n",
    "axs[0].hist(doc_sent_len, bins=max(doc_sent_len));\n",
    "axs[0].set_xlabel('Number of words')\n",
    "axs[0].set_ylabel('Number of documents')\n",
    "axs[1].hist(summ_sent_len, bins=max(summ_sent_len));\n",
    "axs[1].set_xlabel('Number of words')\n",
    "axs[1].set_ylabel('Number of summaries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "        num_rows: 33711\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "        num_rows: 8428\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tifu.train_test_split(test_size=0.1)\n",
    "dataset = tifu['train'].train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> title: thinking my boss wanted to hook up with me.\n",
      ">> documents: throwaway for obvious reasons. keeping it short since the title is the  ...\n",
      ">> summary: version.\n",
      "\n",
      ">> title: singing my way by frank sinatra\n",
      ">> documents: this story takes place about a week ago and i only now can laugh about it enough to post about it. ...\n",
      ">> summary: lost some clients by taking some 7-11 boner pills, got laughed out of a midget boxing match and got roughed up by ladyboys for singing a taboo karaoke song\n",
      "\n",
      ">> title: steaming my clothes\n",
      ">> documents: though technically occurring last night, i'm still dealing with the aftermath....\n",
      ">> summary: steamed shirts in hotel shower. fell asleep.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        title, doc, summ = example['title'], example['documents'], example['tldr']\n",
    "        print(f\">> title: {title}\")\n",
    "        print(\">> documents: {0}...\".format(doc[:doc.find('\\n')]))\n",
    "        print(f\">> summary: {summ}\\n\")\n",
    "\n",
    "show_samples(dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([sent > 512 for sent in summ_sent_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madisonthantu/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"documents\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"tldr\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e426a9a8799c43879dcd5d5785afefe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f81c9d638fb41c5be0fef23a038beff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_tifu = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaf5d6b4e7d42e4a67be1a78790a440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 16.17 GB, other allocations: 1.23 GB, max allowed: 18.13 GB). Tried to allocate 768.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/madisonthantu/Desktop/COMS 6998/Final Project/recursive_LLMs/dataset_exploration.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/madisonthantu/Desktop/COMS%206998/Final%20Project/recursive_LLMs/dataset_exploration.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:1582\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1580\u001b[0m     \u001b[39m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1582\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1583\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1584\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1585\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1586\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1587\u001b[0m     )\n\u001b[1;32m   1588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1589\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1894\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2775\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2776\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2779\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/trainer.py:2801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2800\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2801\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2802\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1709\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1707\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1709\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1710\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1711\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1712\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1713\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1714\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1715\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1716\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1717\u001b[0m     )\n\u001b[1;32m   1718\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1719\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1720\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1721\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1722\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1723\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1123\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1111\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1112\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     )\n\u001b[1;32m   1122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1124\u001b[0m         hidden_states,\n\u001b[1;32m   1125\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1126\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1127\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1128\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1129\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1130\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1131\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1132\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1133\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1134\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1135\u001b[0m     )\n\u001b[1;32m   1137\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:695\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    696\u001b[0m     hidden_states,\n\u001b[1;32m    697\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    698\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    699\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    700\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    701\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    702\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    703\u001b[0m )\n\u001b[1;32m    704\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    705\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:602\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m ):\n\u001b[1;32m    601\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 602\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    603\u001b[0m         normed_hidden_states,\n\u001b[1;32m    604\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    605\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    606\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    607\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    608\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    609\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    612\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:565\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    561\u001b[0m scores \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_bias_masked\n\u001b[1;32m    562\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(scores\u001b[39m.\u001b[39mfloat(), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype_as(\n\u001b[1;32m    563\u001b[0m     scores\n\u001b[1;32m    564\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mdropout(\n\u001b[1;32m    566\u001b[0m     attn_weights, p\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining\n\u001b[1;32m    567\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m layer_head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/COMS 6998/Final Project/recursive_LLMs/langgen/lib/python3.10/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 16.17 GB, other allocations: 1.23 GB, max allowed: 18.13 GB). Tried to allocate 768.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_tifu[\"train\"],\n",
    "    eval_dataset=tokenized_tifu[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'langgen (Python 3.10.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
