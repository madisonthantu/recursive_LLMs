# recursive_LLMs
Repository for course project for COMS 6998 - Language Generation &amp; Summarization

### Abstract ... *in progress*
State of the art large language models (LLMs) are trained on enormous amounts of data and billions of parameters, and the scaling laws for neural language models (Kaplan et al., 2020) indicates that this size plays a crucial role in model performance. Given the vast amounts of training data required, these datasets are typ- ically procured via web scraping, such as the Common Crawl dataset1, which is comprised of nearly 20TB of text data and was used to train GPT-3 (Brown et al., 2020). The deploy- ment of LLMs is already changing the informa- tion landscape—the European Union Agency for Law Enforcement Cooperation estimates that, by 2026, up to 90% of online content may be synthetically generated2 . Given the necessity of web scraping in LLM dataset cu- ration, AI-generated content will not only satu- rate the Internet, but also the data that is used to train those very models. Although LLMs demonstrate striking capabilities, they do not replicate human use of language and are as- sociated with numerous limitations, such as hallucinations, bias and toxicity, and lack of transparency. Consequently, understanding the effects of training these models on data gener- ated by their own species is crucial—and is the motivation behind this present research project. This research will evaluate the qualitative and quantitative effects that generational LLM self- consumption has on text output for three dif- ferent base LLMs, where each generation is fine-tuned on synthetic data generated by the previous generation. The qualitative metrics of interest include emotion intensity, bias and toxicity, and formality.
